# Music Recommendation System Configuration
# Two-phase training: Encoder (audio -> embeddings) + Classifier (embeddings -> ratings)
#
# MODEL VERSIONING & COMPATIBILITY:
#   Encoder and Classifier have SEPARATE versions with dependency tracking:
#
#   - encoder_version: Version of the audio encoder (e.g., "v1", "v2")
#   - classifier_version: Version of the rating classifier (e.g., "v1", "v2")
#
#   RULES:
#   1. Classifier stores which encoder_version it was trained with
#   2. Classifier can be updated independently IF encoder hasn't changed
#   3. If Encoder is updated, Classifier MUST be retrained
#   4. Deployment FAILS if Classifier's encoder_version != current Encoder version
#
# INCREMENTAL TRAINING WORKFLOW:
#   # Train v1 (initial)
#   ./run_music_pipeline.sh all
#
#   # Update classifier only (encoder unchanged)
#   ./run_music_pipeline.sh classifier --classifier-version v2
#
#   # Update encoder (requires new classifier)
#   ./run_music_pipeline.sh encoder --resume-checkpoint checkpoints/encoder_v1_best.pt --encoder-version v2
#   ./run_music_pipeline.sh classifier --classifier-version v1  # New classifier for encoder v2

name: "music_recommendation"
description: "Music recommendation system with two-stage training"
framework: "pytorch"

tags:
  project: "music_recommendation"
  version: "1.0"
  stage: "encoder"  # Change to "classifier" for Stage 2

# Music-specific configuration
music:
  # Clementine database path
  # IMPORTANT: Update this path to match your Clementine database location
  database_path: "/Music/database/clementine_backup_2026-01.db"

  # Embedding storage (SQLite)
  embedding_db_path: "./embeddings.db"

  # Model versioning (see header for rules)
  encoder_version: "v1"  # Version of audio encoder (embeddings tagged with this)
  classifier_version: "v1"  # Version of rating classifier (must match encoder it was trained with)

  # Audio loading parameters
  sample_rate: 16000  # Hz
  audio_duration: 60.0  # seconds (changed from 30s to capture more context from end of songs)
  crop_position: "end"  # Extract from: "start", "center", or "end" (end = last 60s of song)
  normalize: true  # Apply z-normalization (zero mean, unit variance) for consistent amplitude
  max_duration: 900.0  # Skip files >15 minutes (filters live albums, DJ sets, podcasts)

  # Waveform caching (speeds up training by caching resampled audio as .npy files)
  # First epoch populates the cache, subsequent epochs load from cache (~10x faster)
  #
  # CACHE INVALIDATION (automatic):
  #   Cache key = sr{sample_rate}_dur{duration}_{crop_position}_norm{normalize}
  #   Changing ANY of these settings auto-creates a new cache (old cache ignored).
  #
  # WHEN TO MANUALLY CLEAR CACHE (rm -rf ./cache):
  #   - Audio files changed (re-encoded, re-tagged, moved)
  #   - MUSIC_PATH_REMAP environment variable changed
  #   - Corrupted cache (training crashes with "invalid .npy")
  #
  waveform_cache_dir: "./cache"  # Directory for cached waveforms (null = disabled)
  waveform_cache_max_gb: 140  # Max cache size in GB (deletes oldest files when exceeded)

  # Multiprocessing (optimized for parallel audio loading and resampling)
  num_workers: null  # null = 80% of CPU cores (for batch operations)
  dataloader_workers: 12  # Workers for DataLoader (each worker loads+resamples audio in parallel)
  # Note: Audio resampling (e.g., 44100Hz -> 16000Hz) is done in parallel across workers
  # with cached resamplers for efficiency and prefetch_factor=4 for better throughput

  # Speech detection filtering (optional)
  speech_threshold: 0.5  # Filter songs with speech probability > threshold
  speech_results_path: null  # Path to speech detection results (null = skip filtering)

  # Dataset filtering
  # Note: Encoder training includes ALL songs (rated + unrated) for better feature learning
  # Loss is only computed on rated songs (unrated songs have rating=-1 and are masked)
  only_rated: false  # Include unrated songs in encoder training (masked in loss)
  train_split: 0.8  # Train/val split ratio

  # Unknown metadata filtering (for encoder training only)
  # Many tracks have generic placeholder values like "Unknown", "Desconhecido" (Portuguese), etc.
  # These are masked in the loss functions, but if ALL metadata is unknown, the track is skipped.
  # Classifier training will still use these tracks (only needs embeddings + ratings, not metadata)
  skip_unknown_metadata: true  # Skip tracks where artist, album, and title are all unknown

  # Multi-album support
  use_multi_task: false  # If true, enables album classification loss
  album_weight: 0.5  # Weight for album classification loss

# Stage 1: Encoder training hyperparameters
encoder:
  # SimSiam encoder with ResNet backbone on spectrograms
  encoder_type: "simsiam"

  # ------------------------------------------------------------
  # Common settings (used by all encoder types)
  # ------------------------------------------------------------
  embedding_dim: 512
  base_channels: 32  # For backwards compatibility with simple encoder

  # Training
  # epochs: Number of training epochs
  #   - For hyperparameter tuning (HPO): Use 20 epochs for faster trial evaluation
  #   - For final training with optimized hyperparameters: Use final_training_epochs (50 epochs)
  epochs: 20  # Default for HPO trials
  final_training_epochs: 50  # Use this for final training with best hyperparameters
  batch_size: 96  # Increased - resnet34 uses less memory than resnet50
  learning_rate: 0.001

  # Early stopping (especially useful for hyperparameter tuning)
  early_stopping_patience: 10  # Stop if no improvement for N epochs (null = disabled)
  early_stopping_min_delta: 0.0001  # Minimum improvement to count as progress

  # Optimizer (Always use Adam with cosine scheduler for hyperparameter tuning)
  optimizer: "adam"  # Fixed: adam (with cosine scheduler)
  scheduler: "cosine"  # Fixed: cosine annealing

  # Adam optimizer parameters (all tunable via hyperparameter search)
  adam_betas: [0.9, 0.999]  # Coefficients for computing running averages (beta1, beta2)
  adam_eps: 1.0e-08  # Term added to denominator for numerical stability
  adam_weight_decay: 0.0001  # Weight decay (L2 penalty)
  adam_amsgrad: false  # Whether to use AMSGrad variant
  adam_decoupled_weight_decay: false  # If true, uses AdamW-style decoupled weight decay

  # Loss function (NO RATING INFORMATION!)
  loss_type: "metadata_contrastive"  # metadata_contrastive, supervised_contrastive, contrastive, mse
  contrastive_temperature: 0.5

  # Metadata contrastive loss parameters (uses artist/album/year, NOT ratings)
  year_threshold: 5  # Songs within ±N years are considered similar (only if use_year=true)
  use_artist: true   # Same artist = positive pair
  use_album: true    # Same album = positive pair
  use_year: false    # DISABLED: year matching is too weak a signal, causes mode collapse

  # Augmentation-based contrastive learning (same song, different crops = positive pair)
  use_augmentation: true  # Enable dual-crop augmentation for guaranteed positive pairs
  crop_jitter: 5.0        # Random offset in seconds for second crop (creates variety)
  noise_level: 0.005      # Add small white noise (std dev) to augmentations

  # SimSiam encoder settings
  simsiam:
    # Backbone architecture
    backbone: "resnet34"        # "resnet18", "resnet34", "resnet50" - using resnet34 for balance
    pretrained_backbone: false  # Use ImageNet weights for backbone?

    # MLP architecture
    projection_dim: 2048        # Output dimension of projection MLP (z)
    predictor_hidden_dim: 512   # Bottleneck dimension in predictor MLP

    # Spectrogram settings
    n_mels: 128                 # Number of mel frequency bins
    n_fft: 2048                 # FFT window size
    hop_length: 512             # Hop length for STFT

    # Audio augmentation pipeline
    augmentation:
      time_stretch_range: [0.8, 1.2]   # Speed up/slow down factor range
      pitch_shift_range: [-2, 2]       # Semitones to shift
      noise_snr_range: [15, 30]        # Signal-to-noise ratio in dB
      spec_augment: true               # Enable SpecAugment (time/freq masking)
      frequency_mask_param: 27         # Max frequency bins to mask
      time_mask_param: 100             # Max time frames to mask
      volume_change_db: 6              # Random gain ±N dB

    # Training (SimSiam works better with SGD + momentum)
    optimizer: "sgd"            # "sgd" or "adam"
    sgd_momentum: 0.9           # Momentum for SGD
    sgd_weight_decay: 0.0005    # Weight decay for SGD
    sgd_learning_rate: 0.03     # Base learning rate for SGD (with cosine decay)

# Stage 2: Classifier training hyperparameters
classifier:
  # Model architecture
  hidden_dims: [256, 128]
  dropout: 0.3
  use_batch_norm: False

  # Training
  # epochs: Number of training epochs
  #   - For hyperparameter tuning (HPO): Use 20 epochs for faster trial evaluation
  #   - For final training with optimized hyperparameters: Use final_training_epochs (50 epochs)
  epochs: 20  # Default for HPO trials
  final_training_epochs: 50  # Use this for final training with best hyperparameters
  batch_size: 64
  learning_rate: 0.0005

  # Early stopping (especially useful for hyperparameter tuning)
  early_stopping_patience: 10  # Stop if no improvement for N epochs (null = disabled)
  early_stopping_min_delta: 0.0001  # Minimum improvement to count as progress

  # Optimizer (Always use Adam with cosine scheduler for hyperparameter tuning)
  optimizer: "adam"  # Fixed: adam (with cosine scheduler)
  scheduler: "cosine"  # Fixed: cosine annealing

  # Adam optimizer parameters (all tunable via hyperparameter search)
  adam_betas: [0.9, 0.999]  # Coefficients for computing running averages (beta1, beta2)
  adam_eps: 1.0e-08  # Term added to denominator for numerical stability
  adam_weight_decay: 0.00001  # Weight decay (L2 penalty)
  adam_amsgrad: false  # Whether to use AMSGrad variant
  adam_decoupled_weight_decay: false  # If true, uses AdamW-style decoupled weight decay

  # Loss function
  loss_type: "mse"  # mse

# MLflow configuration
mlflow:
  tracking_uri: "http://localhost:5000"
  experiment_name: "music_recommendation"
  artifact_location: "./mlruns"
  backend_store_uri: "sqlite:///mlflow.db"
  auto_start: true

# Hyperparameter tuning configuration (optional)
tuning:
  tuner_type: "optuna"
  n_trials: 100
  timeout: null

  sampler: "TPESampler"
  pruner: "MedianPruner"

  # Search space for encoder
  encoder_search_space:
    parameters:
      learning_rate:
        type: "loguniform"
        low: 0.0005
        high: 0.001
      batch_size:
        type: "categorical"
        choices: [64,]
      embedding_dim:
        type: "categorical"
        choices: [2048,]
      base_channels:
        type: "categorical"
        choices: [64,]

      # Adam optimizer parameters (all tunable)
      adam_beta1:
        type: "uniform"
        low: 0.85
        high: 0.95
      adam_beta2:
        type: "uniform"
        low: 0.99
        high: 0.9999
      adam_eps:
        type: "loguniform"
        low: 1.0e-10
        high: 1.0e-06
      adam_weight_decay:
        type: "loguniform"
        low: 1.0e-06
        high: 1.0e-02
      adam_amsgrad:
        type: "categorical"
        choices: [false, true]
      adam_decoupled_weight_decay:
        type: "categorical"
        choices: [false, true]

  # Search space for classifier
  classifier_search_space:
    parameters:
      learning_rate:
        type: "loguniform"
        low: 0.0005
        high: 0.001
      batch_size:
        type: "categorical"
        choices: [64,]
      dropout:
        type: "float"
        low: 0.01
        high: 0.5
      hidden_dims:
        type: "categorical"
        choices: [[512, 256, 128],]

      # Adam optimizer parameters (all tunable)
      adam_beta1:
        type: "uniform"
        low: 0.85
        high: 0.95
      adam_beta2:
        type: "uniform"
        low: 0.99
        high: 0.9999
      adam_eps:
        type: "loguniform"
        low: 1.0e-10
        high: 1.0e-06
      adam_weight_decay:
        type: "loguniform"
        low: 1.0e-07
        high: 1.0e-03
      adam_amsgrad:
        type: "categorical"
        choices: [false, true]
      adam_decoupled_weight_decay:
        type: "categorical"
        choices: [false, true]

# Reproducibility
seed: 42
deterministic: true

# Device configuration
device: "cuda"  # cuda, cpu, mps
gpu_memory_limit_gb: 30  # Limit GPU memory usage
precision: "bf16-mixed"  # Use "bf16-mixed" for RTX 5090 (Blackwell) to save memory

# Paths
checkpoint_dir: "./checkpoints"
artifact_dir: "./artifacts"

# Recommendation generation
recommendations:
  top_n: 100  # Number of songs to recommend
  output_format: "xspf"  # xspf, json, csv
  output_path: "./recommendations.txt"
  output_dir: "/Music/recommendations"  # Directory for playlist files
  min_rating_threshold: 0.6  # Only recommend songs with predicted rating > threshold

  # Human-in-the-loop reinforcement learning (HITL)
  # These playlists help improve the model through active learning
  human_feedback_uncertain: 100  # Top-N uncertain predictions (recommender_help.xspf)
  human_feedback_best: 50  # Top-N best predictions for validation (recommender_best.xspf)
