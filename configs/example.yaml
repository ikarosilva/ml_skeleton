# Example configuration for ml_skeleton
# This can be used as a template for your experiments

name: "example_experiment"
description: "Example experiment configuration"
framework: "pytorch"

tags:
  project: "example"
  version: "1.0"

# Default hyperparameters (used for single runs or as base values)
hyperparameters:
  epochs: 20
  batch_size: 32
  learning_rate: 0.001

# MLflow configuration
mlflow:
  tracking_uri: "http://localhost:5000"
  experiment_name: "example_experiment"
  artifact_location: "./mlruns"
  backend_store_uri: "sqlite:///mlflow.db"
  auto_start: true

# Hyperparameter tuning configuration
tuning:
  tuner_type: "optuna"  # "optuna", "ray_tune", or "none"
  n_trials: 50
  timeout: null  # seconds, null for unlimited

  # Optuna-specific
  sampler: "TPESampler"  # TPESampler, CmaEsSampler, RandomSampler
  pruner: "MedianPruner"  # MedianPruner, HyperbandPruner, NopPruner

  # Ray Tune-specific (if using ray_tune)
  scheduler: "ASHAScheduler"
  search_alg: "OptunaSearch"
  num_samples: 50
  max_concurrent_trials: 4
  resources_per_trial:
    cpu: 4
    gpu: 1

  # Search space definition
  search_space:
    parameters:
      learning_rate:
        type: "loguniform"
        low: 0.00001
        high: 0.1
      batch_size:
        type: "categorical"
        choices: [16, 32, 64, 128]
      hidden_size:
        type: "categorical"
        choices: [128, 256, 512]
      dropout:
        type: "float"
        low: 0.0
        high: 0.5

# Reproducibility
seed: 42
deterministic: true

# Paths
checkpoint_dir: "./checkpoints"
artifact_dir: "./artifacts"
